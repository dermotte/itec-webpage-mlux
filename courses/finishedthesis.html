
<h1 class="sectionedit1" id="finished_bakkalaureat">Finished Bakkalaureat</h1>
<div class="level1">

</div>
<!-- EDIT1 SECTION "Finished Bakkalaureat" [1-36] -->
<h2 class="sectionedit2" id="index_for_cbir">Index for CBIR</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Students: Anna-Maria Pasterk, Christoph Kofler</div>
</li>
<li class="level1"><div class="li"> Finished: June 2009</div>
</li>
</ul>

<p>
Content Based Image retrieval allows to search for images based on their color &amp; texture characteristics. There are several libraries providing this functionality for arbitrary applications and one of them is <a href="http://freshmeat.net/projects/lirecbir/" class="urlextern" title="http://freshmeat.net/projects/lirecbir/"  rel="nofollow">LIRE</a>. Within this project a spatial access method for LIRE will be developed to support retrieval in large image databases. 
</p>

</div>
<!-- EDIT2 SECTION "Index for CBIR" [37-519] -->
<h2 class="sectionedit3" id="online_video_portal">Online Video Portal</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Students: Qian Wu, Junyun Yang</div>
</li>
<li class="level1"><div class="li"> Finished: Sept. 2007</div>
</li>
</ul>

<p>
YouTube, Revver, Metacafe and MyVideo are very popular although they use simple methods and low quality video. Within this project a video portal has been implemented. The video portal allows upload, annotation and transcoding of videos and offers therefore a platform for users to share their content. The project was implemented in Ruby on Rails using FFMPEG for transcoding and the <a href="http://www.jeroenwijering.com/?item=JW_FLV_Media_Player" class="urlextern" title="http://www.jeroenwijering.com/?item=JW_FLV_Media_Player"  rel="nofollow">JW FLV Player</a> for video viewing.
</p>

</div>
<!-- EDIT3 SECTION "Online Video Portal" [520-1092] -->
<h2 class="sectionedit4" id="user_behaviour_classification">User Behaviour Classification</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Students: C. Kofler</div>
</li>
</ul>

<p>
Users behave based on their intentions. In the web we can roughly separate the roles of surfers, browsers and searchers with a focus on multimedia content. Within this work the user should be classified in this schema (or a more detailed one) based on her/his behaviour. A logging tool (client, server or intermediate) for a users behaviour should be developed within this thesis.
</p>

</div>
<!-- EDIT4 SECTION "User Behaviour Classification" [1093-1542] -->
<h2 class="sectionedit5" id="content_based_auto-tagging">Content Based Auto-Tagging</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Students: A. Pitman</div>
</li>
</ul>

<p>
Typically one out of five users tag their images when they upload them on the web. Those tags – being simple keywords from an uncontrolled vocabulary – help a lot for retrieval and organisation of multimedia assets. In this project a method for tag recommendation will be developed. It will utilize the existing tagged photos of Flickr and tries to suggest tags based on the image content.
</p>

</div>
<!-- EDIT5 SECTION "Content Based Auto-Tagging" [1543-1999] -->
<h2 class="sectionedit6" id="employing_local_features_image_repository_browsing">Employing Local Features Image Repository Browsing</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Students: L. Esterle</div>
</li>
</ul>

<p>
Images that have overlapping regions can be indexed using an ontology describing their spatial relation (overlap, inclusion, and where in the image). Within this project an appropriate ontology has to be found and images should be automatically indexed using the ontology using local features like SURF.
</p>

</div>
<!-- EDIT6 SECTION "Employing Local Features Image Repository Browsing" [2000-2394] -->
<h2 class="sectionedit7" id="human_computation_for_image_video_summarization">Human Computation for Image &amp; Video Summarization</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Students: A. M&uuml;ller</div>
</li>
</ul>

<p>
Like in ESP game, where images get labeled through a fun game, a game for image summarization will be developed. 1-4 players watch a image, where parts are covered. Over time more and more of the image is visible. The players select one out of a list of labels describing the image best as soon as they recognize. In an extension of the work on images a game for videos has been developed.
</p>

</div>
<!-- EDIT7 SECTION "Human Computation for Image & Video Summarization" [2395-2874] -->
<h2 class="sectionedit8" id="personal_multimedia_metadata_recorder">Personal Multimedia + Metadata Recorder</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Students: M. Guggenberger</div>
</li>
</ul>

<p>
When taking a photo with a mobile phone many different aspects of the situation sensed by the phone are not stored within the image. The same goes for video and audio recording. Within this projects an application for multimedia capturing will be developed, which maximizes the amount of metadata stored with the multimedia content (sensor readings, WLAN SSIDs, bluetooth IDs, etc.). 
</p>

</div>
<!-- EDIT8 SECTION "Personal Multimedia + Metadata Recorder" [2875-] -->